# 周报

by Vieran

## 本周工作总结

### QuEST

2. 修复了GPU下优化后代码的精度问题——CPU优化代码上删减的一些“冗余”运算在GPU上不能删，会出现精度问题，这是由浮点运算的非结合性引起的（另，发现即使是CPU优化后的代码，在算例小的情况下也会出现精度问题，但是没有GPU下的明显
2. 将CPU的优化代码改为GPU编程的代码（cpu和gpu之间内存交流问题、CUDA的线程执行顺序问题等，learn a lot from this

### 基础知识学习

1. 学习如何“熟练”使用vim、git和脚本协助工作（前所未有地感受到了它们的强大
2. 学习了Linux命令行下使用gdb调试代码（core dump
3. 加深了对CUDA内存模型的理解（如何使用shared memory实现简单的类似cpu的cache功能？尝试了几种办法，但是都没有达到效果；经过讨论，重新整理思绪，准备进行下一次尝试

总结：这周是熟悉CUDA编程、和bug作斗争以及对代码进行各种各样的尝试的一周

## 下周工作

- [ ] 在代码中实现CUDA的shared memory管理

  想法：在gate fusion得到一串可以连续执行的门之后，调用kernel函数（`问题1：如何分配block和thread`）处理这一串门的执行；kernel函数中，申请一块shared memory提供给各个门（门是通过再次调用device函数实现的，也就是\_\_global\_\_函数内调用多个\_\_device\_\_函数）进行访问，这里就是模仿了cpu上的L1 cache（`问题2：当所需要的数组块大于shared memory的最大可用空间时，如何进行块的轮替`；`问题3：如何设计以使得每个device函数充分利用kernel内的线程`；`问题4：当完成了门的计算之后，如何将shared memory的内容写回（由于门之间是有顺序要求的，这其实是一个隐藏的块内线程同步问题）`）——这些问题，或多或少我已经得到了初步的答案，但是我需要再仔细推敲确认无误之后才能付诸行动（如果没有想好就下手写代码，就可能会像之前失败的尝试一样，浪费时间而没有效果，汲取教训×）